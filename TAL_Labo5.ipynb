{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\"/>\n",
    "\n",
    "# Cours TAL - Laboratoire 5\n",
    "# Applications du modèle word2vec\n",
    "\n",
    "**Objectifs**\n",
    "\n",
    "Comparer des modèles word2vec pré-entraînés sur l’anglais avec des modèles appris localement sur\n",
    "deux corpus, en les appliquant à des tâches de mesures de similarité et d’analogie entre mots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consignes\n",
    "* Soumettre sur Cyberlearn un notebook Jupyter avec les expériences, les résultats obtenus et leur\n",
    "analyse. Bien présenter les étapes suivies, et répondre clairement aux questions posées dans\n",
    "l’énoncé. Bien préciser les données et les commandes utilisées.\n",
    "* Le travail est à effectuer en binôme.\n",
    "* Ne pas hésiter à consulter la documentation de Gensim sur word2vec, ainsi que celle sur les\n",
    "KeyedVectors, qui forment une classe plus générale avec plusieurs exemples intéressants.\n",
    "* Les différentes tâches se feront soit sur votre propre ordinateur (si vous disposez d’au moins 16\n",
    "Go de RAM), soit sur un notebook fourni par le service Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1. Tester et évaluer un modèle entraîné sur Google News\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Installez gensim, la bibliothèque implémentant les outils pour travailler avec Word2Vec ( pip\n",
    "install --upgrade gensim ). Puis chargez le modèle word2vec pré-entraîné sur le corpus\n",
    "Google News en écrivant : w2v_model = gensim.downloader.load(\"word2vec-google-news-\n",
    "300\") , ce qui télécharge le fichier la première fois, et enfin en ne gardant que les vecteurs de\n",
    "mots, avec « w2v_vectors = w2v_model.wv » puis « del w2v_model » ).\n",
    "Si on dispose du fichier en local, on peut le charger en écrivant w2v_vectors =\n",
    "KeyedVectors.load_word2vec_format(path_to_file, binary=True) . \n",
    "\n",
    "### Quelle place mémoire occupe le processus du notebook une fois les vecteurs de mots chargés ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w2v_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vectors = w2v_model.wv\n",
    "del w2v_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le processus du notebook a l'air d'occuper 4.5 GiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ? Et quelle est la taille du vocabulaire du modèle ? Identifiez cinq mots qui sont dans le vocabulaire et un qui ne l’est pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile, common_texts\n",
    "\n",
    "fname = get_tmpfile(\"vectors.kv\")\n",
    "w2v_vectors.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vectors = KeyedVectors.load(fname, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pizza: ', len(w2v_vectors['Pizza']))\n",
    "print('Spaghetti: ', len(w2v_vectors['Spaghetti']))\n",
    "print('Hamburger: ', len(w2v_vectors['Hamburger']))\n",
    "print('Cheesecake: ', len(w2v_vectors['Cheesecake']))\n",
    "print('Brownie: ', len(w2v_vectors['Brownie']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dimension de l'espace vectoriel d'un vecteur semble être **300**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  print('COVID-19: ', len(w2v_vectors['COVID-19']))\n",
    "except:\n",
    "  print(\"Not in vocabulary\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size\n",
    "\n",
    "print(\"La taille est de: \", len(w2v_vectors.vocab.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Comment peut-on mesurer la distance entre deux mots dans cet espace ? Calculez par exemple la distance entre les mots rabbit et carrot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_w2v(word1, word2):\n",
    "    return w2v_vectors.distance(word1, word2)\n",
    "\n",
    "distance = dist_w2v(\"rabbit\", \"carrot\")\n",
    "print(\"{:.1f}\".format(distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Testez le modèle de distance entre mots. Est-ce que des mots proches sémantiquement sont aussi proches dans l’espace vectoriel, et inversement ? Testez au moins cinq paires de mots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def eval_dist(words):\n",
    "    comb = list(combinations(words, r=2))\n",
    "\n",
    "    for p in comb: \n",
    "        distance = dist_w2v(p[0], p[1])\n",
    "        print(\"Distance between: \", p, \"{:.1f}\".format(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_words = [\"booze\", \"alcohol\", \"brew\", \"wine\", \"cocktail\", \"beer\", \"ethanol\"]\n",
    "\n",
    "eval_dist(some_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alcohol et ethanol sont techniquement la même chose, mais ont une distance très élevée.\n",
    "Le sens scientifique éloigne probablement. \n",
    "\n",
    "Wine, beer et booze sont proches. Brew et beer aussi. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Y a-t-il des cas ambigus, et pourquoi selon vous ? Par exemple, pouvez-vous trouver des mots opposés selon le sens qui sont proches dans l’espace réduit ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_words = [\"joy\", \"sadness\", \"happiness\", \"mournful\", \"delight\"]\n",
    "\n",
    "\n",
    "eval_dist(other_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joy est à la même distance de sadness et happiness. Rigolo :)\n",
    "\n",
    "L'exemple ci-dessus démontre quelques cas amusants.\n",
    "\n",
    "Joy est proche de happiness et delight, mais entre eux happiness et delight sont très éloignés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Que dire des mots ayant plusieurs sens ? Pouvez-vous donner 3 exemples de ce problème ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_words = [\"run\", \"sprint\", \"escape\", \"jog\", \"start\"]\n",
    "\n",
    "\n",
    "eval_dist(other_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run est réputé pour avoir plusieurs signifiés.\n",
    "\n",
    "Ici on voit pourtant que run n'est proche d'aucun de ces synonymes. \n",
    "\n",
    "source: https://www.thesaurus.com/browse/run?s=t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. En vous aidant de la documentation de Gensim sur KeyedVectors, mesurez de manière quantitative la performance du modèle sur le corpus WordSimilarity-353. Expliquez ce que signifient vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n",
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h. De même, en vous inspirant de la documentation, évaluez le modèle sur les données de test appelées questions-words.txt. Pouvez-vous expliquer ce que mesure ce test ? Les résultats du modèle sont-ils satisfaisants ? Commentez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "analogy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entraîner et tester deux nouveaux modèles à partir de corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tal",
   "language": "python",
   "name": "tal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
